{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is your Downloaded Blueprint Notebook ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags to identify this iteration when submitted\n",
    "# example: codex_tags = {'env': 'dev', 'region': 'USA', 'product_category': 'A'}\n",
    "\n",
    "codex_tags = {1:'App DEmo'\n",
    "}\n",
    "\n",
    "from codex_widget_factory import utils\n",
    "results_json=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_gender_barplot='''\n",
    "#Library Imports\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from plotly.io import to_json\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import date\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "#Function Calls\n",
    "def get_ingested_data(file_path, datasource, connection_uri, container_name):\n",
    "    block_blob_service = BlockBlobService(connection_string=connection_uri)\n",
    "    blob_data = block_blob_service.get_blob_to_text(container_name=container_name,\n",
    "                                                    blob_name=file_path)\n",
    "    ingested_df = pd.DataFrame()\n",
    "    ingested_df = pd.read_csv(StringIO(blob_data.content))\n",
    "    return ingested_df\n",
    "data_source = 'azure_blob_storage'\n",
    "connection_string = 'DefaultEndpointsProtocol=https;AccountName=willbedeletedsoon;AccountKey=qa5A74pLx0IQxOJk4MGoQChO8kJW6u9rjUBQj8gOeL3bPADodK27ExoEMY/Gq1BIY1tDk9hEWQT+JcnhDO79SQ==;EndpointSuffix=core.windows.net'\n",
    "container_name = 'ddrs-training-2023-codx'\n",
    "\n",
    "file_path='titanic.csv'\n",
    "ingested_data=get_ingested_data(file_path,data_source,connection_string,container_name) #data Ingestion\n",
    "#Fill Null values to avoid any issues while deploying application\n",
    "ingested_data=ingested_data.fillna(\"-\")\n",
    "gender_count=ingested_data['sex'].value_counts().to_frame().reset_index()\n",
    "gender_count.rename(columns={\"index\":'Gender','sex':\"Count of Genders\"},inplace=True)\n",
    "gender_count=gender_count.iloc[0:2,:]\n",
    "#Preparation of plotly figure\n",
    "fig=go.Figure()\n",
    "fig.add_trace(go.Bar(x=gender_count['Gender'],y=gender_count['Count of Genders'],name=' Count of Gender'))\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.update_yaxes(title='Count')\n",
    "# assigning to bridge variables\n",
    "dynamic_outputs=to_json(fig)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_overview_details='''\n",
    "#Library Imports\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "from plotly.io import to_json\n",
    "from azure.storage.blob import BlockBlobService\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from datetime import date\n",
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "#Function Calls\n",
    "def get_ingested_data(file_path, datasource, connection_uri, container_name):\n",
    "    block_blob_service = BlockBlobService(connection_string=connection_uri)\n",
    "    blob_data = block_blob_service.get_blob_to_text(container_name=container_name,\n",
    "                                                    blob_name=file_path)\n",
    "    ingested_df = pd.DataFrame()\n",
    "    ingested_df = pd.read_csv(StringIO(blob_data.content))\n",
    "    return ingested_df\n",
    "def get_response_table(response):\n",
    "    table_header = response.columns.values.tolist()\n",
    "    table_data = response.values.tolist()\n",
    "    return {\n",
    "        \"multiple_tables\": False,\n",
    "        \"table_headers\": table_header,\n",
    "        \"table_data\": table_data,\n",
    "    }\n",
    "data_source = 'azure_blob_storage'\n",
    "connection_string = 'DefaultEndpointsProtocol=https;AccountName=willbedeletedsoon;AccountKey=qa5A74pLx0IQxOJk4MGoQChO8kJW6u9rjUBQj8gOeL3bPADodK27ExoEMY/Gq1BIY1tDk9hEWQT+JcnhDO79SQ==;EndpointSuffix=core.windows.net'\n",
    "container_name = 'ddrs-training-2023-codx'\n",
    "\n",
    "file_path='titanic.csv'\n",
    "#data ingestion\n",
    "ingested_data=get_ingested_data(file_path,data_source,connection_string,container_name) #data Ingestion\n",
    "#Fill Null values to avoid any issues while deploying application\n",
    "#data preparation before adding to conversion function\n",
    "ingested_data=ingested_data.fillna(\"-\")\n",
    "table_data=ingested_data[['name','age','cabin','survived']]\n",
    "table_data['survived']=np.where(table_data['survived']==1,'Yes',table_data['survived'])\n",
    "table_data['survived']=np.where(table_data['survived']==0,'No',table_data['survived'])\n",
    "#creating object to be converted to JSON using \n",
    "table_dict=get_response_table(table_data)\n",
    "#assign to bridge variable\n",
    "dynamic_outputs=json.dumps(table_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_dict={}\n",
    "\n",
    "plots_dict={'Gender Ratio of Passengers':count_of_gender_barplot,\n",
    "           'Passenger Overview':passenger_overview_details}\n",
    "\n",
    "metrics={}\n",
    "results_json.append({\n",
    "    'type':'review',\n",
    "    'name': 'overview',\n",
    "    'component':'overview',\n",
    "    'dynamic_visual_results': plots_dict,\n",
    "    'dynamic_code_filters':filters_dict,\n",
    "    'dynamic_metrics_results':metrics\n",
    "           \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please save and checkpoint notebook before submitting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Fundamentals_of_Application_Deployments_202304071220.ipynb to script\n",
      "[NbConvertApp] Writing 5194 bytes to Fundamentals_of_Application_Deployments_202304071220.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "currentNotebook = 'Fundamentals_of_Application_Deployments_202304071220.ipynb'\n",
    "\n",
    "!jupyter nbconvert --to script {currentNotebook} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['codex_widget_factory']\n",
      "SUCCESS | Submitted config params.\n"
     ]
    }
   ],
   "source": [
    "#Submission Link\n",
    "utils.submit_config_params(url='https://codx-pod1-platform-api.azurewebsites.net/codex-api/projects/upload-config-params/x-cE1rb0UP4Sm46n9Qj7wg', nb_name=currentNotebook, results=results_json, codex_tags=codex_tags, args={})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
